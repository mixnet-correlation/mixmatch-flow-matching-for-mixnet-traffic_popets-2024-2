{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0482e9de-4424-4f10-bbeb-3176b92ed890",
   "metadata": {},
   "source": [
    "## Produce TRAIN, VAL, TEST Subsets for all Experiment Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c47543-8270-415b-829d-09b698a6b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import join\n",
    "from json import dump as json_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc59cc2-f55a-4a6a-adde-92f6416f35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIFY BEGIN ###\n",
    "\n",
    "# List all experiment names that you want to compute the dataset subsets for.\n",
    "EXP_NAMES = [\n",
    "    \"exp01_nym-binaries-1.0.2_static-http-download\",\n",
    "    \"exp02_nym-binaries-1.0.2_static-http-download_no-client-cover-traffic\",\n",
    "    \"exp05_nym-binaries-1.0.2_static-http-download_shorter-mix-delay\",\n",
    "    \"exp06_nym-binaries-1.0.2_static-http-download_longer-mix-delay\",\n",
    "    \"exp07_nym-binaries-1.0.2_static-http-download_network-delay\",\n",
    "    \"exp08_nym-binaries-v1.1.13_static-http-download\",\n",
    "]\n",
    "\n",
    "# Specify base path to where above processed datasets reside.\n",
    "DATASET_DIRS_PARENT = \"/PRIVATE_PATH/\"\n",
    "\n",
    "# Specify the target dataset size in number flowpairs.\n",
    "# Pick a number that can be cleanly split according to 70%-15%-15%.\n",
    "DATASET_TARGET_SIZE = 35000\n",
    "\n",
    "###  MODIFY END  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce75837-9206-445a-8894-83df01501981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of flowpairs in each subset.\n",
    "DATASET_TRAIN_SIZE = int(DATASET_TARGET_SIZE * 0.7)\n",
    "DATASET_VAL_SIZE = int(DATASET_TARGET_SIZE * 0.15)\n",
    "DATASET_TEST_SIZE = int(DATASET_TARGET_SIZE * 0.15)\n",
    "\n",
    "assert DATASET_TRAIN_SIZE + DATASET_VAL_SIZE + DATASET_TEST_SIZE == DATASET_TARGET_SIZE, \\\n",
    "    f\"Dataset subset sizes ({DATASET_TRAIN_SIZE} + {DATASET_VAL_SIZE} + {DATASET_TEST_SIZE}) don't add up to {DATASET_TARGET_SIZE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a7fd36-904b-4582-a504-0669d9239024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_subsets(dataset_dir: str, dataset_deepcoffea_dir: str, flowpairs_unsorted: list):\n",
    "    \"\"\"\n",
    "    Takes care of splitting a given flowpairs dataset into 3 non-overlapping subsets: TRAIN, VAL, and TEST.\n",
    "    The resulting partitions will be written into the relevant dataset repositories.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"---\\nDetermining TRAIN, VAL, TEST subsets for dataset '{dataset_dir}'...\\n\")\n",
    "    print(f\"[@] {len(flowpairs_unsorted)=:,}\\n\")\n",
    "    \n",
    "    # Ensure dataset is large enough.\n",
    "    assert len(flowpairs_unsorted) >= DATASET_TARGET_SIZE, f\"Dataset needs to have at least {DATASET_TARGET_SIZE:,} flowpairs, only got: {len(flowpairs_unsorted)=:,}\"\n",
    "    \n",
    "    # Extract only the sorting-relevant folder name of each flowpair and sort\n",
    "    # the entire list of flowpair IDs using Python's sorted default behavior.\n",
    "    flowpairs = sorted(list(map(lambda path: path.rsplit(sep = \"/\", maxsplit = 2)[1], flowpairs_unsorted)))\n",
    "    \n",
    "    # Ensure that indeed every flowpair folder is unique and thus an identifier.\n",
    "    flowpairs_unique = set(flowpairs)\n",
    "    assert len(flowpairs) == len(flowpairs_unique), f\"Some flowpair folder names occurr multiple times: {len(flowpairs)=} != {len(flowpairs_unique)=}\"\n",
    "    \n",
    "    # Split dataset according to 70%-15%-15% rule (TRAIN, VAL, TEST).\n",
    "    flowpairs_train = flowpairs[:DATASET_TRAIN_SIZE]\n",
    "    flowpairs_val = flowpairs[DATASET_TRAIN_SIZE:(DATASET_TRAIN_SIZE + DATASET_VAL_SIZE)]\n",
    "    flowpairs_test = flowpairs[(DATASET_TRAIN_SIZE + DATASET_VAL_SIZE):(DATASET_TRAIN_SIZE + DATASET_VAL_SIZE + DATASET_TEST_SIZE)]\n",
    "    \n",
    "    assert len(flowpairs_train) + len(flowpairs_val) + len(flowpairs_test) == DATASET_TARGET_SIZE\n",
    "    assert len(list(set(flowpairs_train).intersection(set(flowpairs_val)))) == 0, \"Unexpected overlap between TRAIN and VAL dataset subset\"\n",
    "    assert len(list(set(flowpairs_train).intersection(set(flowpairs_test)))) == 0, \"Unexpected overlap between TRAIN and TEST dataset subset\"\n",
    "    assert len(list(set(flowpairs_val).intersection(set(flowpairs_test)))) == 0, \"Unexpected overlap between VAL and TEST dataset subset\"\n",
    "    \n",
    "    # Write subsets to files.\n",
    "    \n",
    "    with open(join(dataset_dir, \"flowpairs_train.json\"), \"w\", encoding = \"utf-8\") as flowpairs_train_fp:\n",
    "        json_dump(flowpairs_train, flowpairs_train_fp, indent = 4)\n",
    "        flowpairs_train_fp.write(\"\\n\")\n",
    "        \n",
    "    with open(join(dataset_deepcoffea_dir, \"flowpairs_train.json\"), \"w\", encoding = \"utf-8\") as flowpairs_train_fp:\n",
    "        json_dump(flowpairs_train, flowpairs_train_fp, indent = 4)\n",
    "        flowpairs_train_fp.write(\"\\n\")\n",
    "\n",
    "    with open(join(dataset_dir, \"flowpairs_val.json\"), \"w\", encoding = \"utf-8\") as flowpairs_val_fp:\n",
    "        json_dump(flowpairs_val, flowpairs_val_fp, indent = 4)\n",
    "        flowpairs_val_fp.write(\"\\n\")\n",
    "    \n",
    "    with open(join(dataset_deepcoffea_dir, \"flowpairs_val.json\"), \"w\", encoding = \"utf-8\") as flowpairs_val_fp:\n",
    "        json_dump(flowpairs_val, flowpairs_val_fp, indent = 4)\n",
    "        flowpairs_val_fp.write(\"\\n\")\n",
    "    \n",
    "    with open(join(dataset_dir, \"flowpairs_test.json\"), \"w\", encoding = \"utf-8\") as flowpairs_test_fp:\n",
    "        json_dump(flowpairs_test, flowpairs_test_fp, indent = 4)\n",
    "        flowpairs_test_fp.write(\"\\n\")\n",
    "    \n",
    "    with open(join(dataset_deepcoffea_dir, \"flowpairs_test.json\"), \"w\", encoding = \"utf-8\") as flowpairs_test_fp:\n",
    "        json_dump(flowpairs_test, flowpairs_test_fp, indent = 4)\n",
    "        flowpairs_test_fp.write(\"\\n\")\n",
    "    \n",
    "    # Print boundary flowpair elements for comparison purposes.\n",
    "    print(f\"[@] TRAIN:\\n    => number of flowpairs: {len(flowpairs_train):,}\\n    => first element: {flowpairs_train[0]}\\n    => last element: {flowpairs_train[-1]}\\n\")\n",
    "    print(f\"[@] VAL:\\n    => number of flowpairs: {len(flowpairs_val):,}\\n    => first element: {flowpairs_val[0]}\\n    => last element: {flowpairs_val[-1]}\\n\")\n",
    "    print(f\"[@] TEST:\\n    => number of flowpairs: {len(flowpairs_test):,}\\n    => first element: {flowpairs_test[0]}\\n    => last element: {flowpairs_test[-1]}\\n\")\n",
    "    \n",
    "    print(\"Done!\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bddb5870-88f3-4a0a-8983-fbd4d4f1a746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Determining TRAIN, VAL, TEST subsets for dataset '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_filtered-to-start-end'...\n",
      "\n",
      "[@] len(flowpairs_unsorted)=35,266\n",
      "\n",
      "[@] TRAIN:\n",
      "    => number of flowpairs: 24,500\n",
      "    => first element: 11TgjQ9kVbUxCUTbrkhW7mUfSU4PFVtqce1qoahhuXa_FFMoBNCmrNXo6JBMFnTTcadAAVbGJqjhaC4p2beH5HaF\n",
      "    => last element: DiE5kfjw2jFPZgM8Eno13eW3hE53Q65A479vw3FBksLa_4EyCsvcNPQQPCmurVgyLnixb3cStGQUMi2EzP9mFpFPG\n",
      "\n",
      "[@] VAL:\n",
      "    => number of flowpairs: 5,250\n",
      "    => first element: DiHW4d2zBHUkZT3euLnyfbE6jyzvHnNfHN8rKBhhMVcx_3QgYx1QZCBymzcuF2b3K7VYXAUzdFHXBuQJxxX76auA3\n",
      "    => last element: GE1j8uRUteQB4JoCtswuXoc3CN5FZCsc5vBXNzjCtWVB_ADmXmkHYmX24hsqkG2xpcK16GUi8Z793zDzDE3f5cAdb\n",
      "\n",
      "[@] TEST:\n",
      "    => number of flowpairs: 5,250\n",
      "    => first element: GE2m6XfAsCm2iMzPYFFjfXEF8Na8DNxkadvFXrNNFips_HoLCd9zqncRTMW2EuLcEDHQpFB87EURAE6CSgSNnNjq\n",
      "    => last element: sMT66cxno4AiBHjd1SSPMALMMiusVJLft4E2eucUT1k_CksiyLbajLCaFYJwGnP7GuyAiVwTxJHiKXw33VpzPnW2\n",
      "\n",
      "Done!\n",
      "---\n",
      "\n",
      "---\n",
      "Determining TRAIN, VAL, TEST subsets for dataset '/PRIVATE_PATH/dataset_exp02_nym-binaries-1.0.2_static-http-download_no-client-cover-traffic_filtered-to-start-end'...\n",
      "\n",
      "[@] len(flowpairs_unsorted)=35,263\n",
      "\n",
      "[@] TRAIN:\n",
      "    => number of flowpairs: 24,500\n",
      "    => first element: 11ffJYo8AVV3AeKP6q7oG7SSG7g9Xo3SpBFpo2kTAua_HoiQCDZEzFPa3adc2BtkVDwcxdtCip5SB3EWeX95Q5iD\n",
      "    => last element: DoC4exMjY1ahZsSwhK6CdgFDC3FuEwwvk1PnSVVcNoTk_7YnnYRJ812Y2V1o1UConYNibHw9qpdbnkRmzDfF7KJms\n",
      "\n",
      "[@] VAL:\n",
      "    => number of flowpairs: 5,250\n",
      "    => first element: DoEo237Nq1Xq8NcqfrmigrT4yVyd7tNkKcQdD3EBmgHh_BCjn1ZA7wRW3absXhjyLfFWiTnrc9fUNLsa4nf7UqADK\n",
      "    => last element: GKFcqWvGkWwRayMxquKAGdvsmYwGrCsPRjKEd8FrPVii_32Z11JNQHZFY7pXpTz817nCNM8D3ogxGZs9WqNgZQncQ\n",
      "\n",
      "[@] TEST:\n",
      "    => number of flowpairs: 5,250\n",
      "    => first element: GKHPxidDhNU2LEGAU75VyWmrzSx25ywUmXHNRV1mwtvv_FAhNeiuzU22uHACh8maPdUnHqvj4PCo4LEjTpsNpVjvX\n",
      "    => last element: tBt3zghTjikHBiaJSsWgwDUUz1w9nppg16AMKCopxgy_EGbc1su8H7dzG5PCeSuYwqxS6rtfMrUhsnFsvUPr2wPm\n",
      "\n",
      "Done!\n",
      "---\n",
      "\n",
      "---\n",
      "Determining TRAIN, VAL, TEST subsets for dataset '/PRIVATE_PATH/dataset_exp05_nym-binaries-1.0.2_static-http-download_shorter-mix-delay_filtered-to-start-end'...\n",
      "\n",
      "[@] len(flowpairs_unsorted)=37,160\n",
      "\n",
      "[@] TRAIN:\n",
      "    => number of flowpairs: 24,500\n",
      "    => first element: 11J3CtyZK5sD3AhqJxoF4Lp4sqvKpbsQEBT7b7D3Ln8_AKf3CkVctjTv2XKzm4PDH7kqk7TPujU8qRyMXqDWcMup\n",
      "    => last element: DCcJzhpDjGfuDkNHc5hMpKbTQTv4T343pQiJfi5t1QZu_8QcdarGQnBPrnJS3m6ERWeYVFc2U1ZCBAqFAXzQimoT1\n",
      "\n",
      "[@] VAL:\n",
      "    => number of flowpairs: 5,250\n",
      "    => first element: DCccue7owF5bGz4YvKkJYXge9T1gy7LL1c9e372F61Z3_6mFxCMQQhRVUoa6feqX2CVpK7sxSvac3XvFXUEyfF8gX\n",
      "    => last element: FarQFgCrB8CrnZXUsWiahLgF2quPbv5MFi6TKLreHAao_DDrZbB7Kzk5gKperUYEiQ99DvnbhFgfp6sa4J9bPUiFf\n",
      "\n",
      "[@] TEST:\n",
      "    => number of flowpairs: 5,250\n",
      "    => first element: Fas5ncqHYcsSRBnoZ5ANHZEjtaWd1TEbVaRoaQsdQyRF_4BxF66BJHWySiLJP3ncV3oyvw9LScNfe411CiY3ueXnd\n",
      "    => last element: Hx1b2YLPb8NtvX83G9LbqeeHJkvwdssE47HKQcj43QBc_ByDmWJ7KSt63cz9cStf8xPSRuiu5G11LW8yzMvfSCT9J\n",
      "\n",
      "Done!\n",
      "---\n",
      "\n",
      "---\n",
      "Determining TRAIN, VAL, TEST subsets for dataset '/PRIVATE_PATH/dataset_exp06_nym-binaries-1.0.2_static-http-download_longer-mix-delay_filtered-to-start-end'...\n",
      "\n",
      "[@] len(flowpairs_unsorted)=35,801\n",
      "\n",
      "[@] TRAIN:\n",
      "    => number of flowpairs: 24,500\n",
      "    => first element: 11FAzqjaoKJAFV1fwGf7pRpufSCCtPYYyJEb1mUdhwX_DQw1BgTxwwfFWvC8mXjbGU8W2gwaF2B3Uxzjrk8j2q4\n",
      "    => last element: DYshZMccHzqrVdqehGqa5BwRgsvwRAS4qKuYMwktypvR_4qDxbjwKfHMZg9fsjCLFQ4huHFXWpiKvGoYPB6qehi3A\n",
      "\n",
      "[@] VAL:\n",
      "    => number of flowpairs: 5,250\n",
      "    => first element: DYtnXiSd9H3PwNg6URJmCf1CDNrVLHpnW1PwZdDZYRc8_56HdZsVttGEY5exoMprfrzeYGii4eMXt2SHVLHMrF9CK\n",
      "    => last element: G1JisyxMMUwB68aiezpB3iXXbrwg8BHvVmbt6jBQCxg_8zmZBkiatNCZnVNjhKLRBmog5hACo8HnJX3PPSfuFp5w\n",
      "\n",
      "[@] TEST:\n",
      "    => number of flowpairs: 5,250\n",
      "    => first element: G1LULGjsEPN9WHepajHMrPHLmrDAzQrenD69PEcQeFBu_BQivXBxRsXMFcYPzffZ4MrrZZpB4Mbv5mF8nAJMdTkiW\n",
      "    => last element: b7QHa3MEnwGDCrupJCa17jU1vdjBdoT9U6htqxpqYRT_8ETMpqDReuuKPfjviVC8CvQMMmhGejpAtwP6uwsyxgUN\n",
      "\n",
      "Done!\n",
      "---\n",
      "\n",
      "---\n",
      "Determining TRAIN, VAL, TEST subsets for dataset '/PRIVATE_PATH/dataset_exp07_nym-binaries-1.0.2_static-http-download_network-delay_filtered-to-start-end'...\n",
      "\n",
      "[@] len(flowpairs_unsorted)=35,585\n",
      "\n",
      "[@] TRAIN:\n",
      "    => number of flowpairs: 24,500\n",
      "    => first element: 123Sjx4Q8i3zBrhavgT9gSUg8Epp6MnBZUyeXtaJBrP1_7GQmjhpDrVYaUMHkU3LFpPhpNjGLr5Mjk6cgjBNTbhy3\n",
      "    => last element: DfWwdbm3rN4tGbXMWWLLZm619rx6DY4WVwt8SMN8EcSF_CpiKfG26TAzQrorr1yF67cwKdTsgw2cNobjdxfywq7bV\n",
      "\n",
      "[@] VAL:\n",
      "    => number of flowpairs: 5,250\n",
      "    => first element: DfXATssBM9YcFcWD7WUqZvknknadFN2SEeQsqpuAzm1f_3grXpPhdPrs8dsqnvTvHGb8NGeJxjUoweFuMe7hWXuKq\n",
      "    => last element: G94V6R5qzjZLS73Vi5JjPZDtyBUMvrN4VDPRWFjg9Vym_URdn3C3nGUSesCJdQe5FLjb2SuntzXc389v2kGKSmGY\n",
      "\n",
      "[@] TEST:\n",
      "    => number of flowpairs: 5,250\n",
      "    => first element: G95RJKNHwBiJ8LxgnroCvE4BCH7HEY66b28mGQ9MNeTT_8oJaG9bHacDuC3dixM2qPV3PG6p4hRzekriDowHD1vB8\n",
      "    => last element: jc4ubzX7xaT27TeeV4yWX5uigfSWqWsyKjwcTrZcjgp_EQPxfV8omcJk5fCxmE3nRMbVT8EbeCyDJcJjPvb1qTc8\n",
      "\n",
      "Done!\n",
      "---\n",
      "\n",
      "---\n",
      "Determining TRAIN, VAL, TEST subsets for dataset '/PRIVATE_PATH/dataset_exp08_nym-binaries-v1.1.13_static-http-download_filtered-to-start-end'...\n",
      "\n",
      "[@] len(flowpairs_unsorted)=35,611\n",
      "\n",
      "[@] TRAIN:\n",
      "    => number of flowpairs: 24,500\n",
      "    => first element: 11o5Uv9riif6JUQTM8fuxDAfn5mZAgncwRbvpqcZaxz_CnnKubFbffsvRxW1DvqpMiWp4hhV5jMVWiKDobTG62Sy\n",
      "    => last element: DcLWuLPx3qA2RCjL912oDH3E9Uh6EeXir3KczfG9qdV2_HKvjeme1qGf4BeV8AHqR7xfsBpgGtWhkaxLoM9FifiMH\n",
      "\n",
      "[@] VAL:\n",
      "    => number of flowpairs: 5,250\n",
      "    => first element: DcMje12ovJWwKnSEjcBsPsGxPox7AgrPWUZJCciUyoDk_8CnDkCAQg96ehW3FAHhKGGkJazuDP87ceA1X9gMLQFcq\n",
      "    => last element: G7ztg6JeXwr8yrsUFxyc6deJ1byc2oCdEXgux53xwErZ_5C1xWpyLngWJNbBxjMt3DBCVLaRRxSdbJM6t82ieeBje\n",
      "\n",
      "[@] TEST:\n",
      "    => number of flowpairs: 5,250\n",
      "    => first element: G82qWNoGBMoxj6LYug2a9VjfXqkonivGMEjKehrcYRwE_557PBtLyoCa4cCZo6pBigA4vBvxsMvGqmzbr5XkrMYJQ\n",
      "    => last element: i9mkjrDfQEbhzDb83Z9rZA9WG9Vb3fjuXWhDiXBPtEg_F1NKEvkM7sDYvKG8vFJDgQA1KSAFGBReHs6CpHjnztuh\n",
      "\n",
      "Done!\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all defined experiments and split their datasets into TRAIN, VAL, and TEST.\n",
    "\n",
    "for exp_name in EXP_NAMES:\n",
    "    \n",
    "    # Build paths to the two respective formats of this dataset.\n",
    "    # The DeepCoFFEA path will only be used for storing the final flowpair lists.\n",
    "    dataset_dir = join(DATASET_DIRS_PARENT, f\"dataset_{exp_name}_filtered-to-start-end\")\n",
    "    dataset_deepcoffea_dir = join(DATASET_DIRS_PARENT, f\"dataset_{exp_name}_format-deepcoffea_filtered-to-start-end\")\n",
    "    \n",
    "    # Find all flowpairs in this dataset.\n",
    "    flowpairs = glob(join(dataset_dir, \"*\", \"flowpair.json\"))\n",
    "    \n",
    "    # Split dataset into TRAIN, VAL, and TEST subsets.\n",
    "    determine_subsets(dataset_dir, dataset_deepcoffea_dir, flowpairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
