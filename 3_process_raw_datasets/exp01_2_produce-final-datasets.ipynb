{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac8867ad-f855-4172-8176-214d4ec47da3",
   "metadata": {},
   "source": [
    "## Produce Datasets in Our Format, DeepCoFFEA Format, and MixCorr Format from Raw `exp01` Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c82bc5-e4c9-49f9-ada3-cd07c646ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os import makedirs\n",
    "from shutil import rmtree\n",
    "from datetime import datetime\n",
    "from os.path import join\n",
    "\n",
    "from lib_analyze_exps import parse_run, create_mixcorr_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8412a99-c801-43c6-ba8b-28ab60145bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIFY BEGIN ###\n",
    "\n",
    "# Specify the name of the experiment that is supposed to be processed from raw.\n",
    "EXP_NAME = \"exp01_nym-binaries-1.0.2_static-http-download\"\n",
    "\n",
    "# Specify parent directory of raw experimental results directory.\n",
    "RAW_EXP_DIR_PARENT = \"/PRIVATE_PATH/\"\n",
    "\n",
    "###  MODIFY END  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c506f72-2f98-49e8-b315-722522a1fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct paths to:\n",
    "#   * RAW_EXP_DIR => raw experimental result files repository,\n",
    "#   * PROC_EXP_DIR_OUR => processed version of the dataset in our flowpair format after running this notebook,\n",
    "#   * PROC_EXP_DIR_DCOFFEA => processed version of the dataset in DeepCoFFEA flowpair format after running this notebook,\n",
    "#   * PROC_EXP_DIR_MIXCORR => processed version of the dataset in MixCorr flowpair format after running this notebook.\n",
    "#\n",
    "# CAUTION: The filesystem locations PROC_EXP_DIR_* will be deleted if they already exist.\n",
    "RAW_EXP_DIR = join(RAW_EXP_DIR_PARENT, f\"dataset_{EXP_NAME}_raw\")\n",
    "PROC_EXP_DIR_OUR = join(RAW_EXP_DIR_PARENT, f\"dataset_{EXP_NAME}_filtered-to-start-end\")\n",
    "PROC_EXP_DIR_DCOFFEA = join(RAW_EXP_DIR_PARENT, f\"dataset_{EXP_NAME}_format-deepcoffea_filtered-to-start-end\")\n",
    "PROC_EXP_DIR_MIXCORR = join(RAW_EXP_DIR_PARENT, f\"dataset_{EXP_NAME}_format-mixcorr_filtered-to-start-end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0cc64-8868-45b3-809d-578788d502b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete and recreate the final dataset directories.\n",
    "\n",
    "rmtree(PROC_EXP_DIR_OUR, ignore_errors = True)\n",
    "rmtree(PROC_EXP_DIR_DCOFFEA, ignore_errors = True)\n",
    "rmtree(PROC_EXP_DIR_MIXCORR, ignore_errors = True)\n",
    "\n",
    "makedirs(PROC_EXP_DIR_OUR, mode=0o755)\n",
    "makedirs(PROC_EXP_DIR_DCOFFEA, mode=0o755)\n",
    "makedirs(PROC_EXP_DIR_MIXCORR, mode=0o755)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd21b36-78da-4d5f-99de-9b2e91720ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover all succeeded runs to process.\n",
    "runs_succeeded = sorted(glob(join(RAW_EXP_DIR, \"*\", \"exp01_curl_run_*\", \"SUCCEEDED\")))\n",
    "\n",
    "# For exp01, this should give: 35,266.\n",
    "print(f\"{len(runs_succeeded):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17367afe-5ba7-47c0-a569-d6ba43550ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"----- [{datetime.now().strftime('%Y-%m-%d_%H:%M:%S.%f')}] Beginning to process raw exp01 dataset -----\\n\")\n",
    "\n",
    "run_ctr = 1\n",
    "\n",
    "for run_succeeded in runs_succeeded:\n",
    "    \n",
    "    parse_run(\n",
    "        PROC_EXP_DIR_OUR,\n",
    "        PROC_EXP_DIR_DCOFFEA,\n",
    "        run_ctr,\n",
    "        run_succeeded)\n",
    "    \n",
    "    run_ctr += 1\n",
    "\n",
    "print(f\"----- [{datetime.now().strftime('%Y-%m-%d_%H:%M:%S.%f')}] Finished processing raw exp01 dataset -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bacf350-aea8-4bed-b146-21fe4171b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily keep these lines until we run the entire Notebook again.\n",
    "rmtree(PROC_EXP_DIR_MIXCORR, ignore_errors = True)\n",
    "makedirs(PROC_EXP_DIR_MIXCORR, mode=0o755)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06a541d7-7dc4-4f9e-a921-e9b73f078bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- [2023-02-23_13:48:55.820226] Beginning to produce MixCorr-formatted dataset for exp01 -----\n",
      "\n",
      "Considering flowpairs of dataset split 'train' now...\n",
      "Done with flowpairs of dataset split 'train'\n",
      "\n",
      "Considering flowpairs of dataset split 'val' now...\n",
      "Done with flowpairs of dataset split 'val'\n",
      "\n",
      "Considering flowpairs of dataset split 'test' now...\n",
      "Done with flowpairs of dataset split 'test'\n",
      "\n",
      "----- [2023-02-23_14:12:48.861306] Finished producing MixCorr-formatted dataset for exp01 -----\n"
     ]
    }
   ],
   "source": [
    "print(f\"----- [{datetime.now().strftime('%Y-%m-%d_%H:%M:%S.%f')}] Beginning to produce MixCorr-formatted dataset for exp01 -----\\n\")\n",
    "\n",
    "# Create dataset in MixCorr format based on existing dataset in our format.\n",
    "create_mixcorr_dataset(PROC_EXP_DIR_OUR, PROC_EXP_DIR_MIXCORR)\n",
    "\n",
    "print(f\"----- [{datetime.now().strftime('%Y-%m-%d_%H:%M:%S.%f')}] Finished producing MixCorr-formatted dataset for exp01 -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75fda6b7-3753-41a6-8ce4-66703190c27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_from_gateway_ack.01'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_from_gateway_ack.02'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_from_gateway_ack.03'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_from_gateway_ack.04'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_from_gateway_ack.05'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_to_gateway_data.01'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_to_gateway_data.02'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_to_gateway_data.03'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_to_gateway_data.04'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_to_gateway_data.05'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_responder_to_gateway_data.01'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_responder_to_gateway_data.02'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_responder_to_gateway_data.03'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_responder_to_gateway_data.04'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_responder_to_gateway_data.05'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_from_gateway_data.01'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_from_gateway_data.02'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_from_gateway_data.03'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_from_gateway_data.04'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_initiator_from_gateway_data.05'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_responder_from_gateway_ack.01'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_responder_from_gateway_ack.02'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_responder_from_gateway_ack.03'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_responder_from_gateway_ack.04'\n",
      "creating file '/PRIVATE_PATH/dataset_exp01_nym-binaries-1.0.2_static-http-download_format-mixcorr_filtered-to-start-end/train_responder_from_gateway_ack.05'\n"
     ]
    }
   ],
   "source": [
    "# Split files in newly produced MixCorr-formatted dataset of at least 90 MiB into\n",
    "# multiple files in order to be able to commit to GitHub.\n",
    "\n",
    "files_too_large = ! find {PROC_EXP_DIR_MIXCORR} -type f -size +90M\n",
    "\n",
    "for file_too_large in files_too_large:\n",
    "    \n",
    "    ! split --verbose --lines=5000 --numeric-suffixes=01 {file_too_large} {file_too_large}.\n",
    "    ! cat {file_too_large}.?? > {PROC_EXP_DIR_MIXCORR}/tmp_file_too_large\n",
    "    ! cmp --verbose --print-bytes {PROC_EXP_DIR_MIXCORR}/tmp_file_too_large {file_too_large}\n",
    "    ! rm {file_too_large} {PROC_EXP_DIR_MIXCORR}/tmp_file_too_large"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
